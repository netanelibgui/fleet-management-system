#!/usr/bin/env python3
"""
Test script for Ollama API connection with the Personal Coaching Assistant.
"""

import requests
import json
import time
from datetime import datetime

def test_ollama_connection():
    """Test basic connection to Ollama API."""
    print("ğŸ§ª Testing Ollama API Connection...")
    
    try:
        # Test if Ollama server is running
        response = requests.get('http://localhost:11434/api/tags', timeout=5)
        if response.status_code == 200:
            models = response.json()
            print("âœ… Ollama server is running")
            print(f"ğŸ“‹ Available models: {[model['name'] for model in models.get('models', [])]}")
            return True
        else:
            print(f"âŒ Server responded with status: {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("âŒ Cannot connect to Ollama server at localhost:11434")
        print("ğŸ’¡ Make sure Ollama is running: 'ollama serve'")
        return False
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return False

def test_coaching_response():
    """Test the LLM with coaching-specific prompts."""
    print("\nğŸ§  Testing Coaching Assistant Capabilities...")
    
    test_prompts = [
        {
            "name": "Motivation Support",
            "prompt": "You are a personal coach. I'm feeling overwhelmed with my goals. Give me one simple step I can take right now.",
            "expected_keywords": ["step", "simple", "action", "focus"]
        },
        {
            "name": "Habit Formation", 
            "prompt": "You are a personal coach. I want to build a morning routine but keep failing. What's your advice?",
            "expected_keywords": ["small", "consistent", "habit", "routine"]
        },
        {
            "name": "Procrastination Help",
            "prompt": "You are a personal coach. I keep procrastinating on important tasks. Help me break this pattern.",
            "expected_keywords": ["break", "task", "start", "small"]
        }
    ]
    
    for i, test in enumerate(test_prompts, 1):
        print(f"\nğŸ“ Test {i}: {test['name']}")
        print(f"ğŸ”µ Prompt: {test['prompt'][:50]}...")
        
        try:
            start_time = time.time()
            
            response = requests.post('http://localhost:11434/api/generate', 
                json={
                    "model": "mistral:v0.3",
                    "prompt": test['prompt'],
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 200  # Limit response length for testing
                    }
                }, 
                timeout=30)
            
            end_time = time.time()
            response_time = end_time - start_time
            
            if response.status_code == 200:
                result = response.json()
                response_text = result.get('response', '').strip()
                
                print(f"âœ… Response received ({response_time:.1f}s)")
                print(f"ğŸ“„ Response preview: {response_text[:100]}...")
                
                # Check for coaching-specific keywords
                found_keywords = [kw for kw in test['expected_keywords'] 
                                if kw.lower() in response_text.lower()]
                
                if found_keywords:
                    print(f"ğŸ¯ Coaching keywords found: {found_keywords}")
                else:
                    print("âš ï¸  No coaching keywords detected")
                
                return True
                
            else:
                print(f"âŒ API Error: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ Error during test: {e}")
            return False

def test_system_prompt_adherence():
    """Test if the model follows coaching personality from system prompts."""
    print("\nğŸ­ Testing System Prompt Adherence...")
    
    system_prompt = """You are a direct but compassionate personal coach. Your responses should be:
- Brief and actionable (under 100 words)
- Use "you" and direct language
- Focus on immediate next steps
- Encouraging but realistic
"""
    
    user_prompt = "I failed at my diet again today. I feel terrible."
    
    try:
        response = requests.post('http://localhost:11434/api/generate', 
            json={
                "model": "mistral:v0.3",
                "prompt": f"[INST] {system_prompt}\n\nUser: {user_prompt} [/INST]",
                "stream": False,
                "options": {
                    "temperature": 0.6,
                    "num_predict": 150
                }
            }, 
            timeout=20)
        
        if response.status_code == 200:
            result = response.json()
            response_text = result.get('response', '').strip()
            
            print("âœ… System prompt test completed")
            print(f"ğŸ“„ Response: {response_text}")
            
            # Check response characteristics
            word_count = len(response_text.split())
            has_direct_language = 'you' in response_text.lower()
            is_encouraging = any(word in response_text.lower() 
                               for word in ['can', 'will', 'try', 'step', 'start'])
            
            print(f"ğŸ“Š Analysis:")
            print(f"   - Word count: {word_count} (target: <100)")
            print(f"   - Direct language: {'âœ…' if has_direct_language else 'âŒ'}")
            print(f"   - Encouraging tone: {'âœ…' if is_encouraging else 'âŒ'}")
            
            return True
            
    except Exception as e:
        print(f"âŒ System prompt test failed: {e}")
        return False

def generate_test_report():
    """Generate a comprehensive test report."""
    print("\n" + "="*60)
    print("ğŸ OLLAMA SETUP COMPLETION REPORT")
    print("="*60)
    
    print(f"ğŸ“… Test Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ–¥ï¸  Platform: Windows")
    print(f"ğŸ§  Model: Mistral 7B v0.3")
    print(f"ğŸ”— API Endpoint: http://localhost:11434")
    
    # Run all tests
    connection_ok = test_ollama_connection()
    coaching_ok = test_coaching_response() if connection_ok else False
    system_prompt_ok = test_system_prompt_adherence() if connection_ok else False
    
    print("\nğŸ“‹ TEST RESULTS:")
    print(f"   ğŸ”Œ API Connection: {'âœ… PASS' if connection_ok else 'âŒ FAIL'}")
    print(f"   ğŸ§  Coaching Responses: {'âœ… PASS' if coaching_ok else 'âŒ FAIL'}")
    print(f"   ğŸ­ System Prompts: {'âœ… PASS' if system_prompt_ok else 'âŒ FAIL'}")
    
    overall_success = connection_ok and coaching_ok and system_prompt_ok
    
    print(f"\nğŸ¯ OVERALL STATUS: {'âœ… SUCCESS' if overall_success else 'âŒ NEEDS ATTENTION'}")
    
    if overall_success:
        print("\nğŸ‰ Your local LLM is ready for Personal Coaching Assistant!")
        print("ğŸ”œ Next steps:")
        print("   1. Integrate with WhatsApp automation")
        print("   2. Build RAG knowledge base")
        print("   3. Implement core agent logic")
    else:
        print("\nâš ï¸  Please resolve the issues above before proceeding.")
    
    return overall_success

if __name__ == "__main__":
    print("ğŸš€ Personal Coaching Assistant - Ollama Integration Test")
    print("=" * 60)
    
    success = generate_test_report()
    
    if success:
        print("\nğŸ’¡ Try this command to interact directly:")
        print("   ollama run mistral:v0.3")
        print("\nğŸ“š Model info:")
        print("   - Size: 4.4GB")
        print("   - Context: 32k tokens") 
        print("   - Features: Function calling, multilingual")
    
    exit(0 if success else 1) 